# Иерархическая сегментация

Датасет имеет следующую последовательность вложенных классов

```
├── (0) background
└── body
    ├── upper_body
    |   ├── (1) low_hand
    |   ├── (6) up_hand
    |   ├── (2) torso
    |   └── (4) head
    └── lower_body
        ├── (3) low_leg
        └── (5) up_leg
```
Вручную вбивается словарь названный `classes_hierarchy`, который имеет вид:

```
bg: 0
body:
  lower_body:
    low_leg: 3
    up_leg: 5
  upper_body:
    head: 4
    low_hand: 1
    torso: 2
    up_hand: 6
```
Он при помощи вспомогательных функций переводится в словарь `classes_content`, который показывает, какие лейблы содержит каждый класс на каждой ступени иерархии. Его проще сделаь вручную, но при большом числе классов нужно иметь утилиты для его составления, что реализовано в модуле `hierarchical_utils`

```
'level_1': 
    'body': [1, 6, 2, 4, 3, 5],
 'level_3': 
     'low_hand': [1],
      'up_hand': [6],
      'torso': [2],
      'head': [4],
      'low_leg': [3],
      'up_leg': [5]},
 'level_2': 
     'upper_body': [1, 6, 2, 4], 
     'lower_body': [3, 5]
```

Далее будут испробованы две архитектуры сетей - `SegNet` и `UNet` с 3 вариантами лоссов (`CrossEntropy`, `DiceLoss`,`FocalLoss`). 
Каждый лосс может применяться просто для классификации с 7 классами, а может быть обернут в модуль `HierarchicalLoss`, который разбивает задачу классификации на три задачи классификации и считает лосс на каждом уровне, при этом поддерживая веса классов. Вероятности составных классов считаются как сумма вероятностей его состовляющих. Предполагается, что учет иерархической структуры в лоссе поможет повысить качество иерархических метрик.

Помимо этого имеется два варианта прогноза классов по вероятностям. Первый, `SimpleClassSelector`, выбирает один из семи классов при помощи `argmax`, а затем последующие классы определяются однозначно по заданной иерархии классов. Второй метод, `SmartClassSelector`, считает вероятность класса отдельно на каждом уровне иерархии, а только затем применяет `argmax`.

Также есть возможность выбора билинейного и гауссового сглаживания при ресайзе картинок, и опциональные (синхронные) аугментации картинки и таргета из библиотеки `albumentations`.

# Структура репозитория

+ `models` - модуль с моделями UNet и SegNet. Обе используют одну и ту же функцию `create_convolution_block`. `Segnet` реализован при помощи `max unpooling` с прокидыванием соответствующих индексов из пулинга энкодера в анпулиг декодера. Обе модели умеют сохранять свой аргументы вызова как `self.config`, чтобы потом сохранять его с чекпоинтами. Классы моделей не имеют hardcoded констант и допускают гибкий выбор параметров, осталось только найти достаточно ресурсов чтобы все их перепробовать.
+ `data.py` - содержит `SegDataset`, поддерживает аугментации и разные форматы сглаживания.
+ `hierarchical_utils.py` - две важные функции `aggregate_probs` и `decompose_mask`, первая суммирует вероятности для получения вероятности составных классов, а вторая раскладывает максу из 7 классов на 3 маски для каждого уровня.
+ `loss.py` - содержит класс `HierarchicalLoss`, а также лоссы `DiceLoss`,`FocalLoss` с поддержкой весов классов. Также там лежит утилита подсчета весов классов как обратной частоты. Использует функции из `hierarchical_utils`
+ `metric.py` - реализация метрики `Mean Intersection over Union`
+ `nested_dict.py` - набор утилит для превращения словаря `classes_hierarchy` в `classes_content`. Содержит функцию для подсчета массива всех значений для каждого ключа вложенного словаря, функцию подсчета глубины ключа вложенного словаря, и главное преобразование `class_hierarchy -> class_content`
+ `plotting.py` - позволяет рисовать примеры картинок и их масок, а также рисовать лоссы и метрики. 
+ `selector.py` - реализация селекторов класса, использует функции из `hierarchical_utils`
+ `train.py`, `validate.py` - функции обучения модели и подсчета метрик (обновление среднего и std в онлайн-режиме)

Модуль `plotting.py` позволяет создавать картинки наподобие этих:

Пара изображение-маска из датасета:
![image](https://github.com/user-attachments/assets/a0a52111-8525-4910-b563-dc75a006be7f)

Тройка изображение-маска-предсказанная маска, во время обучения сети:

![image](https://github.com/user-attachments/assets/c3377693-c034-4fcc-9533-de667fab4050)

# Формат экспериментов

В [отдельную папку](https://drive.google.com/drive/folders/1lx91TTd8x-YcChli6SotbwYAtYLPG-7N?usp=sharing) (UPD Colab не помог, папка пустая) на Google Drive сохраняются чекпоинты моделей с отметкой названия эксперимента и времени его запуска. В этой папке с целью избежания путаницы также хранится конфиг следующего вида:

```
augmentations: null
batch_size: 16
loss: CrossEntropyLoss
lr: 0.001
model_params:
  __class__: UNet
  act_class: ReLU
  block_depth: 3
  bottleneck_channels: 128
  channels_array:
  - 64
  - 128
  - 256
  - 512
  conv_kernel_size: 3
  enable_batchnorm: true
  in_channels: 3
  out_channels: 7
  pool_kernel_size: 2
resample: 2
```

# Результаты

## Baseline 

В качестве основы для сравнения выступит `SegNet` с `lr = 1e-4` на 80 эпох с лоссом `CrossEntropy` и следующими параметрами:

```
SegNet(in_channels=3,
       out_channels=N_CLASSES,
       encoder_channels_array = [64,128,256, 512],
       decoder_channels_array = [256, 128, 64, 64],
       pool_kernel_size = 2,
       conv_kernel_size = 5,
       block_depth = 3,
       enable_batchnorm = True,
       act_class = nn.ReLU)
```
По умолчанию `SegDataset` использует `resize` из `Pillow` с параметром ресемплинга `BILINEAR`. Получились следующие результаты:

![image](https://github.com/user-attachments/assets/aadaf56f-60fb-454a-acbf-b1939648310b)

Значение метрики mIoU составило 40%-24%-14% по разным уровням соответственно. При этом `SmartClassSelector` оказывается не таким уж умным и уступает по качеству `SimpleClassSelector`, при этом совпадая на 3 уровне - что и задумано по построению.

## Smoothing

Повторим эксперимент, но поменяем ресемплинг на `LANCZOS`. Получится значение метрики 44%-29%-20%. При тех же параметрах модель быстрее обучается, достигает лучших результатов и даже переобучается. Поэтому во всех следующих экспериментах будет производиться сглаживание `LANCZOS` при ресайзе картинок.

![image](https://github.com/user-attachments/assets/714fdc8d-6d59-4509-9561-45b2c359cc39)

## Augmentations

Попробуем использовать следующие аугментации:

```
import albumentations as A

augs = A.Compose([
    A.RandomSizedCrop(min_max_height=(size[0]//2, size[0]//2), 
        height=size[0], width=size[0], p=0.5,interpolation = INTER_LANCZOS4),
    A.HorizontalFlip(p = 0.5),
    A.VerticalFlip(p = 0.5),
#     A.Rotate(limit = 15, p = 0.5),
#     A.CLAHE(p=0.5),
#     A.RandomBrightnessContrast(p=0.5),
#     A.RandomGamma(p=0.5)
])
```

Однако использование таких аугментаций заметно ухудшает качество модели до 37%-22%-15%, а также требует большего `lr = 1e-3` (в остальных экпериментах `lr = 1e-4`).

![image](https://github.com/user-attachments/assets/e3248427-0051-4dc1-8ad0-09c13b3177d4)

## Dice Loss

Этот лосс дает плохие результаты. Интересной особенностью оказалось то, что много эпох подряд этот лосс не позволял модели предсказывать класс бэкграунда, что отражается постоянным участком на графике. К тому же это единственный случай, где предсказания двух селекторов классов совпадают.

![image](https://github.com/user-attachments/assets/c29f9823-57f4-4903-91ea-225947023500)

## Focal Loss

Являясь лишь небольшой модификацией кросс-энтропии, этот лосс дает примерно такое же качество:

![image](https://github.com/user-attachments/assets/0d4d14e3-c3b0-461b-8959-e41e32681293)

## UNet 

Теперь попробуем обучить `UNet` cо следующими параметрами:

```
UNet(in_channels = 3,
             out_channels = N_CLASSES,
             channels_array = [64, 128, 256, 512],
             bottleneck_channels = 512,
             pool_kernel_size = 2,
             conv_kernel_size = 3,
             block_depth = 3,
             enable_batchnorm = True,
             act_class = nn.ReLU)
```

Мы получим немного лучшие результаты на 3 уровне: 44%-29%-22.5%. Однако нет гарантии того, что так вышло из-за преимуществ архитектуры, а не из-за, скажем, разного числа весов в моделях.

![image](https://github.com/user-attachments/assets/04468ca6-254c-466e-8906-3ee3c8e63a0b)

## Hierarchical Loss

Повторим прошлый эксперимент, заменив `CrossEntropy` на `HierarchicalLoss` с кросс-энтропией в качестве базового лосса. Веса классов рассчитаны на каждом уровне сегментации.

Видно, что сеть переобучается. Однако можно заметить, что лучшие эпохи достигают значения метрики 50% на первом уровне и 32% на втором уровне, и 22% на последнем уровне. То есть первые два уровня сегментации улучшились на +10% по сравнению с прошлым экспериментом. Это логично, так как в этом экперименте модель обучалась предсказывать все уровни напрямую, получая, по факту, сразу три маски. Таким образом, это лучшая идея из всех испробованных - нужно только грамотно составить lr-scheduler чтобы обучение прошло гладко.

![image](https://github.com/user-attachments/assets/f7845077-aff4-4d19-83ef-58d99c7c950e)

# Итоги

Из всех испробованных идей большая часть оказали негативный или нейтральный эффект. Большое позитивное влияние оказали правильный ресемплинг и иерархический лосс. Заметим, что на 3 уровне сегментации обученная здесь модель отстает от SOTA методов в более чем 3 раза. В связи с этим можно представить список идей, которые было бы интересно попробовать, но на которые не хватило времени:

+ finetuning готовых моделей сегментации под данный датасет (будут полезны полученные результаты по иерархическому лоссу)
+ Прибавить к лоссу `Total Variation` штраф предсказанной маски с некоторым весом `lambda`. Это может помочь с "рваными" предсказаниями. У меня был положительный опыт его использования, но не хватило времени.
+ Boundary loss. Другое решение той же самой проблемы.

